<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ja" lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<meta http-equiv="Content-Script-Type" content="text/javascript" />
<meta http-equiv="imagetoolbar" content="no" />
<meta name="description" content="" />
<meta name="keywords" content="" />
<link rel="stylesheet" href="../css/common.css" type="text/css" />
<script type="text/javascript" src="../js/jquery.js"></script>
<script type="text/javascript" src="../js/common.js"></script>
<title>複素ニューラルネットワークの学習法</title>
<!-- google analityics -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35918686-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
<!-- google analityics end -->
</head>
<body>
<div id="top">
<div id="menu">
  <ul>
  <li><a href="../index.html" class="on">別の研究内容を見る</a></li>
  </ul>
</div><!-- /#menu-->

<div id="contents">
<h3>複素ニューラルネットワークとは</h3>
複素ニューラルネットワークは、実ニューラルネットワークの入出力や重みを複素数に拡張したものです。複素数ニューラルネットワークは、周期的な傾向を有するデータを効率良く扱うことができます。例えば、実数の指数関数 <i>exp</i>(<i>x</i>) は単調増加関数ですが、複素関数 <i>exp</i>(<i>x+iy</i>) へ拡張することにより、周期的運動が表現できるようになります。
また、<i>y</i>=0のとき<i>exp</i>(<i>x+iy</i>)は実数関数と等しいので、実数上での特性が損なわれるわけではありません。

<h3>新探索法（可約性写像探索法：Reducibility Mapping Search）</h3>
実・複素ニューラルネットワーク共に適用可能な探索法（学習法）として、可約性写像探索法を提案しています。
この探索法は、学習の停滞地点から再学習する手法ですが、初期値をランダムに変更して独立な学習を繰り返す方法と比較して、数１０倍から数１００倍以上速く学習が進められることが分かっています。
また、従来法と同程度以上の汎化性能が得られています。
<div align="center"><img src="error_bessel.png" width=500></img></br>Fig.1 The transition of the objective function when the reducibility mapping was performed.</div>
<b>可約性写像探索法の適用例</b></br>
　図１にベッセル関数を学習させた時の目的関数の減少過程を示しました。
赤い丸にて学習が局所解に陥りますが、可約性写像探索法の適用により、目的関数が更に減少していきます。

<h3>実と複素ニューラルネットワークの汎化能力の比較</h3>
複素ニューラルネットワークは、周期的な傾向を有するデータに対して、高い汎化能力を発揮します。
図２に学習データ(左図)とテストデータ(右図)を示しました。学習データの第二象限は大きく欠損しているため、テストデータを表現するには高い汎化能力が必要となります。
<div align="center"><img src="euler_teacher.png" width=320></img>
<img src="euler_testdata.png" width=320></img></div>
<div align="center">Fig.2 training data and test data.</div>
<b>テストデータの予測結果</b></br>
　ニューラルネットワークで学習データを学習させた後、テストデータを予測した結果を図３に示しました。左図が実ニューラルネットワーク、右図が複素ニューラルネットワークの出力値で、出力値は赤の丸で示されます。
<div align="center"><img src="rvmlp_euler.png" width=320></img>
<img src="cvmlp_euler.png" width=320></img></div>
<div align="center">Fig.3 predicated value of the test data (by real-valued and complex-valued NN).</div>
実ニューラルネットワークでは、テストデータを十分に表現することが出来ていません。
実ニューラルネットワークを用いて周期性を学習させることは、少量のデータでは困難に思われます。
一方で、複素ニューラルネットワークでは、テストデータを十分に表現できました。

<h3>n-bit パリティー問題の学習</h3>
2-bit 偶数パリティー問題としてXOR問題が知られます。
一般に、n-bit パリティー問題の n が大きくなるほどニューラルネットによる学習が困難となります。
しかし、一定の隠れユニット数を有する複素ニューラルネットワークを用いれば、任意の n-bit パリティー問題を解くことができます。
例えば、３層複素ニューラルネットワークの活性化関数として、以下の周期関数を用いたとき、任意の n-bit パリティー問題は、隠れユニット数１つだけで解くことができます。
<div align="center">
<img src="http://chart.apis.google.com/chart?cht=tx
&chl=g(z)=\frac{1}{1 %2b \sqrt{-1} %2b e^{-z}}" />
</div>
ここで、z は複素数です。

</div><!-- /#contents-->
</div><!-- /#top-->
</body>
</html>
